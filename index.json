[{"authors":["Ruhul Amin","Pranav Garg","Baris Coskun"],"categories":null,"content":"","date":1538352000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1538352000,"objectID":"309b6415567caa79b4e87f9145de8c57","permalink":"https://ruhulsbu.github.io/publication/cadence2018/","publishdate":"2018-10-01T00:00:00Z","relpermalink":"/publication/cadence2018/","section":"publication","summary":"Most traditional unsupervised algorithms for anomaly detection do not work for discrete data, specially when the data dimensions have a very high cardinality. An example of such a multi-dimensional, very high-cardinality discrete data set is CloudTrail event logs, where some of the discrete dimensions, such as the account id, are of the order ~1M. Preliminary experiments using Noise-contrastive Estimation (NCE) based anomaly detection for CloudTrail events suggest that NCE is a good technique for anomaly detection in high-cardinality discrete spaces. The proposed technique models the probability mass function over the discrete space via a deep neural network and uses NCE to estimate the probability mass function; events that have low probabilities are flagged as anomalies. In the internship project, we (1) develop a generalized NCE based deep learning algorithms for anomaly detection over discrete data domains; (2) experimentally validate the performance of the deep learning model; and (3) compare its performance to the current state-of-the-art anomaly detection algorithms.","tags":null,"title":"Anomaly Detection for High Cardinality Discrete Spaces using Noisecontrastive Estimation","type":"publication"},{"authors":["Jason Jones","Ruhul Amin","Jessica Kim","Steven Skiena"],"categories":null,"content":"","date":1538352000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1538352000,"objectID":"3ae490244beb86523afea914f5ad4c0e","permalink":"https://ruhulsbu.github.io/publication/gender2019/","publishdate":"2018-10-01T00:00:00Z","relpermalink":"/publication/gender2019/","section":"publication","summary":"Using a corpus of millions of digitized books, we document the presence and trajectory over time of stereotypical gender associations in the written English language from 1800 to 2000. We employ the novel methodology of word embeddings to quantify Male Gender Bias – the tendency to associate a domain with the male gender.  We measure Male Gender Bias in four stereotypically gendered domains: career, family, science, and arts. We find that stereotypical gender associations in language have decreased over time, but still remain, with career and science terms demonstrating positive Male Gender Bias, and family and arts terms demonstrating negative Male Gender Bias. We also seek evidence of changing associations corresponding to second shift ideology and find partial support. Latent within the text of published English-language books is the gender ideology of modern society, and the magnitude of gendered associations appears to be decreasing over time.","tags":null,"title":"Stereotypical Gender Associations in Language Have Decreased Over Time","type":"publication"},{"authors":["Ruhul Amin","Alisa Yurovsky","Yingtao Tian","Steven Skiena"],"categories":null,"content":"","date":1535760000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1535760000,"objectID":"72d9d7aa7e9e151faa345b54468eab20","permalink":"https://ruhulsbu.github.io/publication/bcb2018/","publishdate":"2018-09-01T00:00:00Z","relpermalink":"/publication/bcb2018/","section":"publication","summary":"Genome annotation is the process of labeling DNA sequences of an organism with its biological features, and is one of the fundamental problems in Bioinformatics. Public annotation pipelines such as NCBI integrate a variety of algorithms and homology searches on public and private databases. However, they build on the information of varying consistency and quality, produced over the last two decades. We identified 12,415 errors in NCBI RNA gene annotations, demonstrating the need for improved annotation programs. We use Recurrent Neural Network (RNN) with Long Short-Term Memory (LSTM) to demonstrate the potential of deep learning networks to annotate genome sequences, and evaluate different approaches on prokaryotic sequences from NCBI database. Particularly, we evaluate DNA K−mer embeddings and the application of RNNs for genome annotation. We show how to improve the performance of our deep networks by incorporating intermediate objectives and downstream algorithms to achieve better accuracy. Our method, called DeepAnnotator, achieves an F-score of 94%, and establishes a generalized computational approach for genome annotation using deep learning. Our results are very encouraging as our method eliminates the requirement of hand crafted features and motivates further research in application of deep learning to full genome annotation. DeepAnnotator algorithms and models can be accessed in Github: https://github.com/ruhulsbu/DeepAnnotator.","tags":["Bioinformatics","Deep Learning"],"title":"DeepAnnotator: Genome Annotation with Deep Learning","type":"publication"},{"authors":["Alisa Yurovsky","Ruhul Amin","Justin Gardin","Yuping Chen","Steven Skiena","Bruce Futcher"],"categories":null,"content":"","date":1534982400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1534982400,"objectID":"566721e1dd78bf752c8ebf2f66665d57","permalink":"https://ruhulsbu.github.io/publication/plos_2018_2/","publishdate":"2018-08-23T00:00:00Z","relpermalink":"/publication/plos_2018_2/","section":"publication","summary":"The Shine-Dalgarno motif occurs in front of prokaryotic start codons, and is complementary to the 3’ end of the 16S ribosomal RNA. Hybridization between the Shine-Dalgarno sequence and the anti-Shine-Dalgarno region of the16S rRNA (CCUCCU) directs the ribosome to the start AUG of the mRNA for translation. Shine-Dalgarno-like motifs (AGGAGG in E. coli) are depleted from open reading frames of most prokaryotes. This may be because hybridization of the 16S rRNA at Shine-Dalgarnos inside genes would slow translation or induce internal initiation. However, we analyzed 128 species from diverse phyla where the 16S rRNA gene(s) lack the anti-Shine-Dalgarno sequence, and so the 16S rRNA is incapable of interacting with Shine-Dalgarno-like sequences. Despite this lack of an anti-Shine-Dalgarno, half of these species still displayed depletion of Shine-Dalgarno-like sequences when analyzed by previous methods. Depletion of the same G-rich sequences was seen by these methods even in eukaryotes, which do not use the Shine-Dalgarno mechanism. We suggest previous methods are partly detecting a non-specific depletion of G-rich sequences. Alternative informatics approaches show that most prokaryotes have only slight, if any, specific depletion of Shine-Dalgarno-like sequences from open reading frames. Together with recent evidence that ribosomes do not pause at ORF-internal Shine-Dalgarno motifs, these results suggest the presence of ORF-internal Shine-Dalgarno-like motifs may be inconsequential, perhaps because internal regions of prokaryotic mRNAs may be structurally “shielded” from translation initiation.","tags":null,"title":"Prokaryotic coding regions have little if any specific depletion of Shine-Dalgarno motifs","type":"publication"},{"authors":["Ruhul Amin","Alisa Yurovsky","Yuping Chen","Steven Skiena","Bruce Futcher"],"categories":null,"content":"","date":1534982400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1534982400,"objectID":"a16115bd9262099c59e1b53203599a55","permalink":"https://ruhulsbu.github.io/publication/plos_2018_1/","publishdate":"2018-08-23T00:00:00Z","relpermalink":"/publication/plos_2018_1/","section":"publication","summary":"We examined 20,648 prokaryotic unique taxids with respect to the annotation of the 3’ end of the 16S rRNA, which contains the anti-Shine-Dalgarno sequence. We used the sequence of highly conserved helix 45 of the 16S rRNA as a guide. By this criterion, 8,153 annotated 3’ ends correctly included the anti-Shine-Dalgarno sequence, but 12,495 were foreshortened or otherwise mis-annotated, missing part or all of the anti-Shine-Dalgarno sequence, which immediately follows helix 45. We re-annotated, giving a total of 20,648 16S rRNA 3’ ends. The vast majority indeed contained a consensus anti-Shine-Dalgarno sequence, embedded in a highly conserved 13 base “tail”. However, 128 exceptional organisms had either a variant anti-Shine-Dalgarno, or no recognizable anti-Shine-Dalgarno, in their 16S rRNA(s). For organisms both with and without an anti-Shine-Dalgarno, we identified the Shine-Dalgarno motifs actually enriched in front of each organism’s open reading frames. This showed to what extent the Shine-Dalgarno motifs correlated with anti-Shine Dalgarno motifs. In general, organisms whose rRNAs lacked a perfect anti-Shine-Dalgarno motif also lacked a recognizable Shine-Dalgarno. For organisms whose 16S rRNAs contained a perfect anti-Shine-Dalgarno motif, a variety of results were obtained. We found one genus, Alteromonas, where several taxids apparently maintain two different types of 16S rRNA genes, with different, but conserved, antiSDs. The fact that some organisms do not seem to have or use Shine-Dalgarno motifs supports the idea that prokaryotes have other robust mechanisms for recognizing start codons for translation.","tags":null,"title":"Re-annotation of 12,495 prokaryotic 16S rRNA 3’ ends and analysis of Shine-Dalgarno and anti-Shine-Dalgarno sequences","type":"publication"},{"authors":null,"categories":null,"content":"Pipilika is mostly known to Bangladeshi people as first Bangladeshi web search engine which developed from Computer Science and Engineering Department of Shahjalal University of Science and Technology, Sylhet. It is the country\u0026rsquo;s first Bangla search engine and evolved from different research initiative. It indexes Bangla and English newspapers, blogs, wikipedia, government sites and different portals of the country, or those portals which is related to Bangladesh. Pipilika is that sort of initiative which builds intelligent products and services powered by machine learning, Data Science and Artificial intelligence. Pipilika’s goal is to help consumers and businesses better navigate the online and offline world related to Bangla content and computation. Since its inception in 2013, we have delivered world-class, locally relevant search and information services to the people of Bangladesh. Additionally, we have developed market-leading on-demand data science services, bangla news , e-commerce related products, and other mobile applications.\n","date":1514764800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1514764800,"objectID":"bfd8edaffb6ab2e8e36ddcca675ab86a","permalink":"https://ruhulsbu.github.io/project/pipilika/","publishdate":"2018-01-01T00:00:00Z","relpermalink":"/project/pipilika/","section":"project","summary":"Pipilika indexes Bangla and English newspapers, blogs, wikipedia, government sites and different portals of the country, or those portals which is related to Bangladesh. Pipilika serve ~3,000 queries/day. Funded by GPIT, Accenture and Access to Information Programme of Primer Minister's Office in Bangladesh","tags":["NLP","Data Science","Deep Learning"],"title":"Pipilika: Bengali Text Search Engine","type":"project"},{"authors":["Noushad Sojib","Saiful Islam","Mehedi Hasan Rupok","Sajid Hasan","Ruhul Amin","M. Zafar Iqbal"],"categories":null,"content":"","date":1513987200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1513987200,"objectID":"15f26f244eeebae0a479a7ae124c52ba","permalink":"https://ruhulsbu.github.io/publication/ribo2017/","publishdate":"2017-12-23T00:00:00Z","relpermalink":"/publication/ribo2017/","section":"publication","summary":"This paper is about the design and development of ”Ribo”, the upper torso enabled social humanoid robot and the mass people's response to it as received at several public exhibition. Ribo is 135cm tall and has necessary actuation in the face to show basic facial expression. The exterior design is especially crafted to make it look more like a social artificial being rather than just a mechanical robot. The robot is optimized by a distributed software architecture which enables modules developed in different programming languages to work in sync. Ribo was presented in several exhibitions in Bangladesh where mass people directly interacted with it. During that time the visitors were asked several questions on the robot's design to rate the social behavior of Ribo. According to the survey, people liked Ribo mostly because of its facial design and how it speaks in their mother tongue.","tags":null,"title":"Design and development of the social humanoid robot named Ribo","type":"publication"},{"authors":["Sunny Chowdhury","K. M. Sajjadul Islam","Sheikh Nabil Mohammad","Ruhul Amin","Choudhury Wahid"],"categories":null,"content":"","date":1512950400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1512950400,"objectID":"be4eafffcaf564d30a810cd6e64c4363","permalink":"https://ruhulsbu.github.io/publication/lis2017/","publishdate":"2017-12-11T00:00:00Z","relpermalink":"/publication/lis2017/","section":"publication","summary":"Due to the geographic location of Bangladesh, heavy rainfall with the thunderstorm is a common phenomenon. Every year lightning causes lots of casualties. There are very few sources available for lightning-related information. Global Hydrology Resource Centre (GHRC) has a huge collection of lightning data from 1998 to April 2015. The other source of lightning is the news incidents published in Newspapers. This paper explores the effects of lightning in Bangladesh during the last several years, by analyzing lightning news from newspapers and Lightning Imaging Sensor (LIS) data from Global Hydrology Resource Center (GHRC). We analyzed LIS data and news data to find the correlation between these datasets. Finally, we report lightning-prone areas with time when lightning mostly occurs in Bangladesh based on those results.","tags":null,"title":"Analysis on Lightning News and Correlation with Lightning Imaging Sensor (LIS) Data","type":"publication"},{"authors":["Sheikh Nabil Mohammad","Sakhawat Hossain","Md Mustafijur Rahman","Mithun Das","Ruhul Amin"],"categories":null,"content":"","date":1512950400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1512950400,"objectID":"ca4f06dc3a5790813acbfecab755a9a1","permalink":"https://ruhulsbu.github.io/publication/sachetan2017/","publishdate":"2017-12-11T00:00:00Z","relpermalink":"/publication/sachetan2017/","section":"publication","summary":"In developing countries such as Bangladesh, social and economic development is often hindered by lack of civilian safety due to increasing crime rate. In this paper, we have attempted to devise a solution to help citizens avoid potentially dangerous locations using data analytics. We designed and developed a system named “Sachetan”, which is a mobile application that enables its users to privately share their own experience of incident occurrences with precise spatial and temporal information. Two data sources are combined and statistical insight and graphical representation of patterns have been presented to the users. In our research, we tried to find the pattern and determine the movements of high-frequency incident areas by analyzing the data.","tags":null,"title":"Sachetan: A Crowdsource-Based Personal Safety Application","type":"publication"},{"authors":["Md. Mahfuzur Rahaman","Ruhul Amin"],"categories":null,"content":"","date":1506729600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1506729600,"objectID":"89934b433c5c9403cc4eac562698d4b5","permalink":"https://ruhulsbu.github.io/publication/keywords2017/","publishdate":"2017-09-30T00:00:00Z","relpermalink":"/publication/keywords2017/","section":"publication","summary":"This article focuses on the keyword extraction process for a document collection. A lot of works have been done on this topic but the performance of those procedures is not satisfactory. Some of those works followed supervised approach using specific corpus whether others used unsupervised approach. Meanwhile, many of those methods work only for a single document. In this paper, we described the simplified steps for extracting keywords from a specific document collection. This method is language independent and can be used for extracting keywords from any language. It uses term frequency, document frequency, chi-square distribution and Tseng's algorithm as part of the whole extraction process.","tags":null,"title":"Language independent statistical approach for extracting keywords","type":"publication"},{"authors":null,"categories":null,"content":"RIBO is a Bengali speaking social humanoid robot that can speak, interact with humans, make facial gestures, handshake and dance. It is being developed by a group: RoboSUST, formed with students from Shahjalal University of Science and Technology. RIBO is currently under research and development. Initially it was made as a project funded by Bangladesh Science Fiction Society and Ministry of ICT, Bangladesh. RIBO v1.0 has only movements in the upper torso. RIBO team plans to develop the robot further and give it proper movements in the legs, so that RIBO can be more socially interact with mass population and aid them in need.\n","date":1483228800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1483228800,"objectID":"64e164744a1fbea57957a1a827e6d558","permalink":"https://ruhulsbu.github.io/project/ribo/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/project/ribo/","section":"project","summary":"Ribo can speak, interact with humans, make facial gestures, handshake and dance. Funded by Science Fiction Society and Ministry of ICT in Bangladesh.","tags":["NLP","AIML","Robotics"],"title":"Ribo: A Social Humanoid Robot.","type":"project"},{"authors":["Adnan Ahmad","Ruhul Amin"],"categories":null,"content":"","date":1482192000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1482192000,"objectID":"5da6e21f4bdbf7ccff8c6b68c70db272","permalink":"https://ruhulsbu.github.io/publication/embeddings2016/","publishdate":"2016-12-20T00:00:00Z","relpermalink":"/publication/embeddings2016/","section":"publication","summary":"In this paper, we present Bengali word embeddings and it's application in the classification of news documents. Word embeddings are multi-dimensional vectors that can be created by exploiting the linguistic context of the words in large corpus. To generate the embeddings, we collected Bengali news document of last five years from the major daily newspapers. Word embeddings are generated using the Neural Network based language processing model Word2vec. We use the vector representations of the Bengali words to cluster them using K-means algorithm. We show that those clusters can be used directly to perform various natural language processing task by solving the problem of Bengali news document classification. We use the Support Vector Machine (SVM) for the classification task and achieve ~91% F1-score. The accuracy of our method demonstrates that our word embeddings could capture the semantics of word from the respective context correctly.","tags":null,"title":"Bengali word embeddings and it's application in solving document classification problem","type":"publication"},{"authors":["Ruhul Amin","Steven Skiena","Michael C. Schatz"],"categories":null,"content":"","date":1476489600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1476489600,"objectID":"1718264ed74f4e1cc3b187eb23e52faa","permalink":"https://ruhulsbu.github.io/publication/iccabs2016/","publishdate":"2016-10-15T00:00:00Z","relpermalink":"/publication/iccabs2016/","section":"publication","summary":"The quality of the Oxford Nanopores long DNA sequence reads has been, to date, lower than other technologies, causing great interest to develop new algorithms that can make use of the data. So far, alignment methods including LAST, BLAST, BWA-MEM and GraphMap have been used to analyze these sequences. However, each of these tools has significant challenges to use with these data: LAST and BLAST require considerable processing time for high sensitivity, BWA-MEM has the smallest average alignment length, and GraphMap aligns many random strings with moderate accuracy. To address these challenges we developed a new read aligner called NanoBLASTer specifically designed for long nanopore reads. In experiments resequencing the well-studied S. cerevisiae (yeast) and Escherichia coli (E. coli) genomes, we show that our algorithm produces longer alignments with higher overall sensitivity than LAST, BLAST and BWA-MEM. We also show that the runtime of NanoBLASTer is faster than GraphMap, BLAST and BWA-MEM.","tags":null,"title":"NanoBLASTer: Fast alignment and characterization of Oxford Nanopore single molecule sequencing reads","type":"publication"},{"authors":["Arzuba Akter","Md Muzahidul Islam","Shakhinur Islam Mondal","Zabed Mahmud","Nurnabi Azad Jewel","Sabiha Ferdous","Ruhul Amin","Md Mahfuzur Rahman"],"categories":null,"content":"","date":1391126400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1391126400,"objectID":"9f148e1bb5d08af79ce6c1460d419593","permalink":"https://ruhulsbu.github.io/publication/mirna2014/","publishdate":"2014-01-31T00:00:00Z","relpermalink":"/publication/mirna2014/","section":"publication","summary":"MicroRNAs (miRNAs) are the group of ∼22 nucleotides long noncoding small endogenous and evolutionary conserved post-transcriptional regulatory RNAs, which show an enormous role in various biological and metabolic processes in both animals and plants. To date not a single miRNA has been identified in coffee (Coffea arabica), which is an economically important plant of Rubiaceae family. In this study a well-developed, powerful and comparative computational approach, EST-based homology search is applied to find potential miRNA of coffee. We blasted publicly available EST sequences obtained from NCBI GenBank against previously known plant miRNAs. For the first time, one potential miRNA from a large miRNA family with appropriate fold back structures was identified through a series of filtration criteria. A total of six potential target genes in Arabidopsis were identified based on their sequence complementarities. The target genes mainly encode transport inhibitor like protein, transcription factor, DNA-binding protein, and GRR1-like protein, and these genes play an important role in various biological processes like response to chitin, cold, salt stress, water deprivation etc. Overall, findings from this study will accelerate the way for further researches of miRNAs and their functions in coffee.","tags":null,"title":"Computational identification of miRNA and targets from expressed sequence tags of coffee (Coffea arabica)","type":"publication"},{"authors":["Ruhul Amin","Bijan Paul","Faisal Ahamed Khan"],"categories":null,"content":"","date":1367452800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1367452800,"objectID":"b64dbfab3b5e442539f93b24a70b59da","permalink":"https://ruhulsbu.github.io/publication/screen2013/","publishdate":"2013-05-02T00:00:00Z","relpermalink":"/publication/screen2013/","section":"publication","summary":"Accessibility of computer for visually impaired people is a Challenging task. This paper presents software named Mongol Dip, which provides audio-based interactive interfaces to help people with visual impairments to explore and navigate windows operating system. In this software we have used text to speech technology (TTS) to echo every operation done by the user. Mongol Dip provides the easiest interface that helps the visually impaired people to access computer. Visually impaired people cannot read out Bangla text document via computer because existing software they use to operate computer do not support Bangla text. Bi-lingual (English \u0026 Bangla Language) support is the main significant part of our software. Hence the main goal of this software is to assist the people with visual impairments to operate computers and connecting with the digital world using minimum operations and maximum usability using bi-lingual TTS support.","tags":null,"title":"Bi-lingual audio assistance supported screen reading software for the people with visual impairments","type":"publication"},{"authors":null,"categories":null,"content":"Mongol Dip is a software for visually impaired people to operate windows operating system for doing computational work. In this software text to speech technology is used to echo every operation done by the user. This software assist people to move through the disk spaces and open documents, rich media files as well as working with these files. Using Mongol Dip people with visual impairments are be able to create or modify documents, sending/receiving e-mails and accessing websites very simply using short cut key combinations.\nThe main objectives of the Mongol Dip are : - Ensuring the access of visually impaired people in the field of ICT. - Providing audio assistance for every operation done by the user. - Providing audio assistance for two languages: Bangla and English. - Providing special browser for managing files and folders easily. - Reading out the contents of any document like text, doc, pdf etc. - Enabling visually impaired people to edit any type of text document. - Providing short cut key combinations to access programs easily. - Install and uninstall any kind of software on the Windows - Sending and receiving email using customized module. - Browsing Internet using Mozilla Firefox browser. - Providing compatibility for both desktop and laptop computer\n","date":1356998400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1356998400,"objectID":"93a44a22ac5649d34f709d4cb9840a8d","permalink":"https://ruhulsbu.github.io/project/mongoldip/","publishdate":"2013-01-01T00:00:00Z","relpermalink":"/project/mongoldip/","section":"project","summary":"This software is used for ICT trainingof blind people by Visually Impaired People Society. Using Mongol Dip people with visual impairments are be able to create or modify documents, sending/receiving e-mails and accessing websites very simply using short cut key combinations. Funded by Ministry of Science and ICT, Bangladesh. ","tags":["NLP","Data Science","HCI"],"title":"Mongol Dip: Bilingual Screen Reading Software for Visually Impaired People.","type":"project"},{"authors":["Md. Eamin Rahman","Rashedul Islam","Shahidul Islam","Shakhinur Islam Mondal","Ruhul Amin"],"categories":null,"content":"","date":1328832000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1328832000,"objectID":"614d5148914f165e861c07f57f52c398","permalink":"https://ruhulsbu.github.io/publication/mirann2012/","publishdate":"2012-02-10T00:00:00Z","relpermalink":"/publication/mirann2012/","section":"publication","summary":"MicroRNA (miRNA) is a special class of short noncoding RNA that serves pivotal function of regulating gene expression. The computational prediction of new miRNA candidates involves various methods such as learning methods and methods using expression data. This article has proposed a reliable model — miRANN which is a supervised machine learning approach. MiRANN used known pre-miRNAs as positive set and a novel negative set from human CDS regions. The number of known miRNAs is now huge and diversified that could cover almost all characteristics of unknown miRNAs which increases the quality of the result (99.9% accuracy, 99.8% sensitivity, 100% specificity) and provides a more reliable prediction. MiRANN performs better than other state-of-the-art approaches and declares to be the most potential tool to predict novel miRNAs. We have also tested our result using a previous negative set. MiRANN, opens new ground using ANN for predicting pre-miRNAs with a promise of better performance.","tags":null,"title":"MiRANN: A reliable approach for improved classification of precursor microRNA using Artificial Neural Network model","type":"publication"},{"authors":null,"categories":null,"content":"Subachan can convert Bengali words to corresponding speech. In doing these tasks, we had to develop a bunch of algorithms for the Bengali language processing. We have developed an algorithm for text normalization implementing the expansion rules based on the grammar of Bengali language. We can detect standard and non-standard words and can resolve abbreviation, as well as we can identify phrase by this algorithm. We have also developed an algorithm for phonetic analysis that converts a Bengali sentence to its phonetics using customized grapheme to phoneme rules developed based on our research on Bengali language. We have also developed a small lexicon which removes the O-karanto problem in Bengali language in some cases. Hence correctness of the Bengali pronunciation is increased. Our approach for diphone reduction makes the system smaller and faster without losing optimal intelligibility and naturalness of the generated speech. We have followed a completely new approach for handling the joint letters in which the developed algorithm transforms a joint letters to the concatenation of diphones, fade in and fade out effect of starting and ending diphones and silence to maintain the artificial stress and pitch.\nWe did not use any kind of transliteration like another Bengali text to speech synthesis software Kotha that use the third party tools Festival, a multi lingual text to speech synthesis system. Again, Our system, Subachan takes around 45 ms to generate a 10 second utterance where as Festival takes 2 seconds to generate a 10 second utterance which is too long. The most important difference is that we have used only 527 diphones as oppose to the 4355 diphones of Kotha. Since most of the speech generation is done algorithmically we could decrease the total number of word-specific information of lexicon in our system. With some exceptions, Subachan can work in any situation and produce better performances. Demonstrated implementation of Subachan produces emotionless speech close to natural language like a news presenter.\n","date":1325376000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1325376000,"objectID":"558ff06c3e7ab2b35e8835bc43c51302","permalink":"https://ruhulsbu.github.io/project/subachan/","publishdate":"2012-01-01T00:00:00Z","relpermalink":"/project/subachan/","section":"project","summary":"This software provide text to speech services to the user of Mongol Dip. Funded by Ministry of Science and ICT, Bangladesh.","tags":["NLP","Speech Synthesis","HCI"],"title":"Subachan: Bengali Text to Speech Synthesis Software.","type":"project"},{"authors":["Ruhul Amin","Asif Mohammed Samir","Madhusodan Chakraborty","MM Rahman"],"categories":null,"content":"","date":1309392000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1309392000,"objectID":"9f7b59e34057239028a74b708147eb60","permalink":"https://ruhulsbu.github.io/publication/sort2011/","publishdate":"2011-06-30T00:00:00Z","relpermalink":"/publication/sort2011/","section":"publication","summary":"This discussion focuses on the sorting algorithm for Bengali language represented by Unicode character set. A few works has been done on this topics but no standard is set up yet to sort Bengali words. Some of these works are based on ASCII representation. To use ASCII, keyboard mapping is important because it is different for each country where the Unicode representation is fixed for all characters of various countries. So, Unicode representation is much more preferable than ASCII representation. In this paper we have discussed about an easy way to sort the Unicode Bengali texts. In our method, a mapping is used which simplified the sorting procedure. This method can sort any Unicode Bengali text and it is not keyboard dependent.","tags":null,"title":"An Efficient Unicode based Sorting Algorithm for Bengali Words","type":"publication"},{"authors":null,"categories":null,"content":"Shahjalal University of Science \u0026amp; Technology, Bangladesh has introduced an SMS based automated registration system for admission tests. Candidates are required to send in their HSC information from any Teletalk prepaid mobile phone. Their information is then processed and verified by the Education Board. After this is completed successfully, the eligible candidates are sent a confirmation message on their mobiles instantly.Finally, the application fee for the admission test is deducted from the candidate’s prepaid mobile account and a notification is sent, again through the SMS channel. All the candidates also receive the admission test seat number via SMS. On the day of the test, the students only need to bring along two attested photographs. The result of the test could again be known using a mobile phone and the students could easily find out their position in merit list.\n","date":1293840000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1293840000,"objectID":"b0bf3bd1648cdf4cdafd5a2883290bb2","permalink":"https://ruhulsbu.github.io/project/admission/","publishdate":"2011-01-01T00:00:00Z","relpermalink":"/project/admission/","section":"project","summary":"This admission system is an innovative solution to the large logistical problem that every university faces in Bangladesh every year. Students from remote part of the country can access the system using SMS. This system received numerous awards for minimizing digital divide. Every educational institute under Ministry of Education use similar system in Bangladesh.","tags":["NLP","HCI"],"title":"Cloud Platform based Digital Admission System","type":"project"},{"authors":["Ruhul Amin","Asif Mohammed Samir","Madhusodan Chakraborty","MM Rahman"],"categories":null,"content":"","date":1292630400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1292630400,"objectID":"2fa9cafcd882cc6b909adf3b134a12dd","permalink":"https://ruhulsbu.github.io/publication/subachan2010/","publishdate":"2010-12-18T00:00:00Z","relpermalink":"/publication/subachan2010/","section":"publication","summary":"This paper discusses the design and development of Text-to-Speech for Bengali language. The major modules of our system are Normalization, Phonetic analysis, Prosodic analysis and Wave synthesis. In normalization process, we have used some modules for example token identification, lookup table, expansion rules for analysing a sentence. Using these modules, we can recognize the type of each word clearly and find out the dependency of the words in a sentence. Normalization solves ambiguity problem and increases correctness. In Phonetic analysis, we have used grapheme to phoneme rules for most of the cases but to solve the problem of O-karanto problem we have used a small dictionary containing the pronunciation of couple of words. And finally we have applied concatenation approach on diphone to develop the system. In ideal situation, our system can produce better performance. And with some exceptions, our synthesis system works well in any situation.","tags":null,"title":"Implementation of Subachan: Bengali text to Speech Synthesis Software","type":"publication"}]